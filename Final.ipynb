{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>date</th>\n",
       "      <th>item_name</th>\n",
       "      <th>item_type</th>\n",
       "      <th>item_price</th>\n",
       "      <th>quantity</th>\n",
       "      <th>transaction_amount</th>\n",
       "      <th>transaction_type</th>\n",
       "      <th>received_by</th>\n",
       "      <th>time_of_sale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>07-03-2022</td>\n",
       "      <td>Aalopuri</td>\n",
       "      <td>Fastfood</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>260</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>Night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>8/23/2022</td>\n",
       "      <td>Vadapav</td>\n",
       "      <td>Fastfood</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>300</td>\n",
       "      <td>Cash</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>Afternoon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>11/20/2022</td>\n",
       "      <td>Vadapav</td>\n",
       "      <td>Fastfood</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>Cash</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>Afternoon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>02-03-2023</td>\n",
       "      <td>Sugarcane juice</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>150</td>\n",
       "      <td>Online</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>Night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>10-02-2022</td>\n",
       "      <td>Sugarcane juice</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>Online</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>Evening</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id        date        item_name  item_type  item_price  quantity  \\\n",
       "0         1  07-03-2022         Aalopuri   Fastfood          20        13   \n",
       "1         2   8/23/2022          Vadapav   Fastfood          20        15   \n",
       "2         3  11/20/2022          Vadapav   Fastfood          20         1   \n",
       "3         4  02-03-2023  Sugarcane juice  Beverages          25         6   \n",
       "4         5  10-02-2022  Sugarcane juice  Beverages          25         8   \n",
       "\n",
       "   transaction_amount transaction_type received_by time_of_sale  \n",
       "0                 260              NaN         Mr.        Night  \n",
       "1                 300             Cash         Mr.    Afternoon  \n",
       "2                  20             Cash         Mr.    Afternoon  \n",
       "3                 150           Online         Mr.        Night  \n",
       "4                 200           Online         Mr.      Evening  "
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"archive/Balaji Fast Food Sales.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   order_id            1000 non-null   int64 \n",
      " 1   date                1000 non-null   object\n",
      " 2   item_name           1000 non-null   object\n",
      " 3   item_type           1000 non-null   object\n",
      " 4   item_price          1000 non-null   int64 \n",
      " 5   quantity            1000 non-null   int64 \n",
      " 6   transaction_amount  1000 non-null   int64 \n",
      " 7   transaction_type    893 non-null    object\n",
      " 8   received_by         1000 non-null   object\n",
      " 9   time_of_sale        1000 non-null   object\n",
      "dtypes: int64(4), object(6)\n",
      "memory usage: 78.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                0\n",
       "date                    0\n",
       "item_name               0\n",
       "item_type               0\n",
       "item_price              0\n",
       "quantity                0\n",
       "transaction_amount      0\n",
       "transaction_type      107\n",
       "received_by             0\n",
       "time_of_sale            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id              0\n",
       "date                  0\n",
       "item_name             0\n",
       "item_type             0\n",
       "item_price            0\n",
       "quantity              0\n",
       "transaction_amount    0\n",
       "transaction_type      0\n",
       "received_by           0\n",
       "time_of_sale          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['transaction_type'] = df['transaction_type'].fillna(\"Credit Card\")\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['received_by'] = df['received_by'].replace(['Mr.','Mrs.'],['Male','Female'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      07-03-2022\n",
       "1       8-23-2022\n",
       "2      11-20-2022\n",
       "3      02-03-2023\n",
       "4      10-02-2022\n",
       "          ...    \n",
       "995     3-19-2023\n",
       "996     9-20-2022\n",
       "997     1-26-2023\n",
       "998     8-27-2022\n",
       "999     5-29-2022\n",
       "Name: date, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['date'] = df['date'].str.replace('/','-')\n",
    "df['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   order_id            1000 non-null   int64         \n",
      " 1   date                1000 non-null   datetime64[ns]\n",
      " 2   item_name           1000 non-null   object        \n",
      " 3   item_type           1000 non-null   object        \n",
      " 4   item_price          1000 non-null   int64         \n",
      " 5   quantity            1000 non-null   int64         \n",
      " 6   transaction_amount  1000 non-null   int64         \n",
      " 7   transaction_type    1000 non-null   object        \n",
      " 8   received_by         1000 non-null   object        \n",
      " 9   time_of_sale        1000 non-null   object        \n",
      "dtypes: datetime64[ns](1), int64(4), object(5)\n",
      "memory usage: 78.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_name ['Aalopuri' 'Vadapav' 'Sugarcane juice' 'Panipuri' 'Frankie' 'Sandwich'\n",
      " 'Cold coffee']\n",
      "item_type ['Fastfood' 'Beverages']\n",
      "transaction_type ['Credit Card' 'Cash' 'Online']\n",
      "received_by ['Male' 'Female']\n",
      "time_of_sale ['Night' 'Afternoon' 'Evening' 'Morning' 'Midnight']\n"
     ]
    }
   ],
   "source": [
    "unique_values = df.select_dtypes(include = 'object').apply(lambda x: x.unique())\n",
    "for column, values in unique_values.items():\n",
    "    print(column, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 47317.93910348191\n",
      "R2 Score: -0.10125138637824915\n",
      "Cross-validation scores: [-0.05239363 -0.17404175 -0.03758828 -0.04087787  0.00551595]\n",
      "Average CV score: -0.05987711638923863\n",
      "\n",
      "Predicted sales: $350.57\n",
      "Recommended staff: 3\n",
      "\n",
      "Feature Importance:\n",
      "        feature  importance\n",
      "2   day_of_year    0.599841\n",
      "3  time_numeric    0.183740\n",
      "0   day_of_week    0.160551\n",
      "1         month    0.044223\n",
      "4    is_weekend    0.011645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering - Extract time-based features\n",
    "# Convert date column to datetime format\n",
    "df['date'] = pd.to_datetime(df['date'], format='mixed')  # Using 'mixed' format to handle different date formats\n",
    "\n",
    "# Now we can extract time-based features\n",
    "df['day_of_week'] = df['date'].dt.dayofweek\n",
    "df['month'] = df['date'].dt.month\n",
    "df['day_of_year'] = df['date'].dt.dayofyear\n",
    "df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "# Create features and target\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Select features with additional meaningful columns\n",
    "# Create time mapping\n",
    "time_mapping = {\n",
    "    'Morning': 0,\n",
    "    'Afternoon': 1,\n",
    "    'Evening': 2,\n",
    "    'Night': 3\n",
    "}\n",
    "\n",
    "# Convert time_of_sale to numeric values\n",
    "df['time_numeric'] = df['time_of_sale'].map(time_mapping)\n",
    "\n",
    "# Now select features\n",
    "features = ['day_of_week', 'month', 'day_of_year', 'time_numeric', 'is_weekend']\n",
    "X = df[features]\n",
    "y = df['transaction_amount']\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=features)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the model with optimized parameters\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = rf_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R2 Score: {r2}')\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(rf_model, X_scaled, y, cv=5)\n",
    "print(f'Cross-validation scores: {cv_scores}')\n",
    "print(f'Average CV score: {cv_scores.mean()}')\n",
    "\n",
    "def predict_staffing_needs(date, time_of_day):\n",
    "    \"\"\"\n",
    "    Predict staffing needs based on expected sales\n",
    "    date: datetime object\n",
    "    time_of_day: 'Morning', 'Afternoon', 'Evening', or 'Night'\n",
    "    \"\"\"\n",
    "    # Create feature vector\n",
    "    features = pd.DataFrame({\n",
    "        'day_of_week': [date.weekday()],  # Changed from day_of_week to weekday()\n",
    "        'month': [date.month],\n",
    "        'day_of_year': [date.timetuple().tm_yday],  # Changed from day_of_year to timetuple().tm_yday\n",
    "        'time_numeric': [time_mapping[time_of_day]],\n",
    "        'is_weekend': [1 if date.weekday() in [5, 6] else 0]  # Changed to use weekday()\n",
    "    })\n",
    "    \n",
    "    # Scale the features\n",
    "    features_scaled = scaler.transform(features)\n",
    "    \n",
    "    # Predict sales\n",
    "    predicted_sales = rf_model.predict(features_scaled)[0]\n",
    "    \n",
    "    # Staffing logic based on sales ranges\n",
    "    if predicted_sales < 100:\n",
    "        return 1, predicted_sales\n",
    "    elif predicted_sales < 250:\n",
    "        return 2, predicted_sales\n",
    "    elif predicted_sales < 400:\n",
    "        return 3, predicted_sales\n",
    "    elif predicted_sales < 600:\n",
    "        return 4, predicted_sales\n",
    "    else:\n",
    "        return 5, predicted_sales\n",
    "\n",
    "# Example usage\n",
    "from datetime import datetime\n",
    "test_date = datetime(2024, 3, 15)\n",
    "staff_needed, predicted_sales = predict_staffing_needs(test_date, 'Evening')\n",
    "print(f'\\nPredicted sales: ${predicted_sales:.2f}')\n",
    "print(f'Recommended staff: {staff_needed}')\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance': rf_model.feature_importances_\n",
    "})\n",
    "print(\"\\nFeature Importance:\")\n",
    "print(feature_importance.sort_values('importance', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pm/z11bn8l91g1_kw05ss7bfjrw0000gn/T/ipykernel_19350/577047174.py:139: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  X = df[features].fillna(method='ffill').fillna(method='bfill')\n",
      "[I 2024-12-03 13:13:50,318] A new study created in memory with name: no-name-a33863c3-db54-47b4-9303-c4aae5d85915\n",
      "[I 2024-12-03 13:13:58,819] Trial 0 finished with value: 0.6362110228482536 and parameters: {'rf_n_estimators': 2615, 'rf_max_depth': 31, 'rf_min_samples_split': 15, 'rf_min_samples_leaf': 3, 'gb_n_estimators': 901, 'gb_learning_rate': 0.013912488716267216, 'gb_max_depth': 10, 'gb_subsample': 0.6102881114021207}. Best is trial 0 with value: 0.6362110228482536.\n",
      "[I 2024-12-03 13:14:04,275] Trial 1 finished with value: 0.6400894381956237 and parameters: {'rf_n_estimators': 2338, 'rf_max_depth': 20, 'rf_min_samples_split': 8, 'rf_min_samples_leaf': 6, 'gb_n_estimators': 490, 'gb_learning_rate': 0.01738396557303579, 'gb_max_depth': 10, 'gb_subsample': 0.8464399182397875}. Best is trial 1 with value: 0.6400894381956237.\n",
      "[I 2024-12-03 13:14:08,456] Trial 2 finished with value: 0.6357455953387199 and parameters: {'rf_n_estimators': 1253, 'rf_max_depth': 29, 'rf_min_samples_split': 13, 'rf_min_samples_leaf': 4, 'gb_n_estimators': 389, 'gb_learning_rate': 0.009313470082345343, 'gb_max_depth': 11, 'gb_subsample': 0.8670463428777693}. Best is trial 1 with value: 0.6400894381956237.\n",
      "[I 2024-12-03 13:14:12,463] Trial 3 finished with value: 0.6819302281657783 and parameters: {'rf_n_estimators': 1477, 'rf_max_depth': 15, 'rf_min_samples_split': 3, 'rf_min_samples_leaf': 7, 'gb_n_estimators': 580, 'gb_learning_rate': 0.005467716133958246, 'gb_max_depth': 6, 'gb_subsample': 0.8184490514514433}. Best is trial 3 with value: 0.6819302281657783.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import optuna\n",
    "\n",
    "def create_advanced_features(df):\n",
    "    # Time-based features\n",
    "    df['hour_of_day'] = pd.Categorical(df['time_of_sale'], \n",
    "                                     categories=['Morning', 'Afternoon', 'Evening', 'Night'],\n",
    "                                     ordered=True).codes\n",
    "    \n",
    "    # Enhanced time-based features\n",
    "    df['day_of_week'] = df['date'].dt.dayofweek\n",
    "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['quarter'] = df['date'].dt.quarter\n",
    "    df['day_of_year'] = df['date'].dt.dayofyear\n",
    "    df['week_of_year'] = df['date'].dt.isocalendar().week\n",
    "    \n",
    "    # Sales patterns\n",
    "    daily_stats = df.groupby(['date', 'time_of_sale'])['transaction_amount'].agg([\n",
    "        'mean', 'count', 'std', 'min', 'max'\n",
    "    ]).reset_index()\n",
    "    df = df.merge(daily_stats, on=['date', 'time_of_sale'], suffixes=('', '_daily'))\n",
    "    \n",
    "    # Rolling statistics\n",
    "    df = df.sort_values('date')\n",
    "    for window in [7, 14, 30]:\n",
    "        df[f'rolling_{window}d_mean'] = df.groupby('time_of_sale')['transaction_amount'].transform(\n",
    "            lambda x: x.rolling(window, min_periods=1).mean())\n",
    "        df[f'rolling_{window}d_std'] = df.groupby('time_of_sale')['transaction_amount'].transform(\n",
    "            lambda x: x.rolling(window, min_periods=1).std())\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_ensemble_model(params):\n",
    "    rf = RandomForestRegressor(\n",
    "        n_estimators=params['rf_n_estimators'],\n",
    "        max_depth=params['rf_max_depth'],\n",
    "        min_samples_split=params['rf_min_samples_split'],\n",
    "        min_samples_leaf=params['rf_min_samples_leaf'],\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    gb = GradientBoostingRegressor(\n",
    "        n_estimators=params['gb_n_estimators'],\n",
    "        learning_rate=params['gb_learning_rate'],\n",
    "        max_depth=params['gb_max_depth'],\n",
    "        subsample=params['gb_subsample'],\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    return VotingRegressor([\n",
    "        ('rf', rf),\n",
    "        ('gb', gb)\n",
    "    ])\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'rf_n_estimators': trial.suggest_int('rf_n_estimators', 1000, 3000),\n",
    "        'rf_max_depth': trial.suggest_int('rf_max_depth', 15, 40),\n",
    "        'rf_min_samples_split': trial.suggest_int('rf_min_samples_split', 2, 15),\n",
    "        'rf_min_samples_leaf': trial.suggest_int('rf_min_samples_leaf', 1, 8),\n",
    "        \n",
    "        'gb_n_estimators': trial.suggest_int('gb_n_estimators', 200, 1000),\n",
    "        'gb_learning_rate': trial.suggest_float('gb_learning_rate', 0.001, 0.1, log=True),\n",
    "        'gb_max_depth': trial.suggest_int('gb_max_depth', 3, 12),\n",
    "        'gb_subsample': trial.suggest_float('gb_subsample', 0.6, 1.0)\n",
    "    }\n",
    "    \n",
    "    ensemble = create_ensemble_model(params)\n",
    "    cv_scores = cross_val_score(ensemble, X_train, y_train, cv=5, scoring='r2', n_jobs=-1)\n",
    "    return cv_scores.mean()\n",
    "\n",
    "def predict_staffing_needs(model, scaler, date, time_of_day, features_list):\n",
    "    \"\"\"\n",
    "    Predict staffing needs based on expected sales\n",
    "    \"\"\"\n",
    "    # Create feature vector for prediction\n",
    "    prediction_df = pd.DataFrame({\n",
    "        'date': [date],\n",
    "        'time_of_sale': [time_of_day]\n",
    "    })\n",
    "    \n",
    "    # Create features for prediction\n",
    "    prediction_df = create_advanced_features(prediction_df)\n",
    "    X_pred = prediction_df[features_list].fillna(0)  # Fill NA with 0 for prediction\n",
    "    \n",
    "    # Scale features\n",
    "    X_pred_scaled = scaler.transform(X_pred)\n",
    "    \n",
    "    # Predict sales\n",
    "    predicted_sales = model.predict(X_pred_scaled)[0]\n",
    "    \n",
    "    # Determine staffing needs based on predicted sales\n",
    "    if predicted_sales < 100:\n",
    "        return 1, predicted_sales\n",
    "    elif predicted_sales < 250:\n",
    "        return 2, predicted_sales\n",
    "    elif predicted_sales < 400:\n",
    "        return 3, predicted_sales\n",
    "    elif predicted_sales < 600:\n",
    "        return 4, predicted_sales\n",
    "    else:\n",
    "        return 5, predicted_sales\n",
    "\n",
    "# Main execution\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Read and prepare data\n",
    "    df = pd.read_csv(\"archive/Balaji Fast Food Sales.csv\")\n",
    "    \n",
    "    # First standardize the date format by replacing '/' with '-'\n",
    "    df['date'] = df['date'].str.replace('/', '-')\n",
    "    \n",
    "    # Then convert to datetime with 'mixed' format\n",
    "    df['date'] = pd.to_datetime(df['date'], format='mixed')\n",
    "    \n",
    "    # Create advanced features\n",
    "    df = create_advanced_features(df)\n",
    "    \n",
    "    # Select features\n",
    "    features = [\n",
    "        'day_of_week', 'month', 'day_of_year', 'hour_of_day', 'is_weekend',\n",
    "        'quarter', 'week_of_year', 'mean', 'count', 'std', 'min', 'max',\n",
    "        'rolling_7d_mean', 'rolling_7d_std',\n",
    "        'rolling_14d_mean', 'rolling_14d_std',\n",
    "        'rolling_30d_mean', 'rolling_30d_std'\n",
    "    ]\n",
    "    \n",
    "    # Prepare data\n",
    "    X = df[features].fillna(method='ffill').fillna(method='bfill')\n",
    "    y = df['transaction_amount']\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_scaled = pd.DataFrame(X_scaled, columns=features)\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Optimize hyperparameters\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=50)\n",
    "    \n",
    "    # Train final model with best parameters\n",
    "    best_params = study.best_params\n",
    "    final_ensemble = create_ensemble_model(best_params)\n",
    "    final_ensemble.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate final model\n",
    "    y_pred = final_ensemble.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f'Final Mean Squared Error: {mse}')\n",
    "    print(f'Final R2 Score: {r2}')\n",
    "    \n",
    "    # Feature importance analysis\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': features,\n",
    "        'importance': final_ensemble.named_estimators_['rf'].feature_importances_\n",
    "    })\n",
    "    print(\"\\nFeature Importance:\")\n",
    "    print(feature_importance.sort_values('importance', ascending=False))\n",
    "    \n",
    "    # Example prediction\n",
    "    future_date = pd.Timestamp('2024-03-15')\n",
    "    staff_needed, predicted_sales = predict_staffing_needs(\n",
    "        final_ensemble, scaler, future_date, 'Evening', features\n",
    "    )\n",
    "    print(f'\\nPrediction for {future_date.date()} Evening:')\n",
    "    print(f'Predicted sales: ${predicted_sales:.2f}')\n",
    "    print(f'Recommended staff: {staff_needed}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
